# RAG Libraries LangChain, HuggingFace

<details><summary>Learning Objectives</summary>

After completing this activity, participants should be able to:
- Explain LangChain and HuggingFace, and their respective role in creating an RAG application 
</details>

<details>

<summary>Description</summary>

There are many tools and libraries available to create an RAG application, but in this module we will focus on two of the more popular tools in the industry: Hugging Face and LangChain


## HuggingFace
Hugging Face is a platform renowned for its transformative contributions to natural language processing (NLP). At the heart of its technical offerings is the Hugging Face Transformers library, a comprehensive open-source repository that houses a diverse array of pre-trained models spanning various NLP architectures. This library is designed to be user-friendly and facilitates straightforward integration of state-of-the-art models into NLP applications.

One key aspect of the technical landscape provided by Hugging Face is the Model Hub, which serves as a centralized repository for hosting, sharing, and accessing pre-trained models. This resource streamlines the process of acquiring and utilizing cutting-edge models for tasks such as text classification, language translation, and sentiment analysis. The platform also offers a range of tokenizers optimized for different languages, contributing to efficient text processing workflows.

Beyond model access, Hugging Face provides tools for fine-tuning and training custom models, enabling users to adapt pre-existing architectures to specific tasks or domains. This technical flexibility empowers developers and researchers to customize and optimize NLP models according to their unique requirements.

In summary, Hugging Face offers a rich ecosystem of pre-trained models, tools for model deployment, and resources for customization. Its technical contributions have significantly influenced the landscape of NLP by democratizing access to cutting-edge technologies and fostering collaboration among practitioners in the field.

## LangChain
Launched in October 2022, LangChain is an open source framework that simplifies the process of creating various generative AI applications. Through various connectors and LangChain Expression Language (LCEL), LangChain provides a simple interface for developers to easily and seamlessly integrate various tools and models they require for their projects. 

LangChain comprises several essential modules designed to facilitate the integration of multiple components required for the development of effective Natural Language Processing (NLP) applications. The following are the overview of the modules:

- The Model Interaction module: also known as model I/O, enables LangChain to engage with various language models, managing inputs to the model and extracting information from its outputs. 
- The Data Connection and Retrieval module: They empower the transformation, storage, and retrieval of data accessed by Large Language Models (LLMs) from databases through queries.
- Chains Module: For more intricate applications, the Chains module serves to link multiple LLMs with other components or additional LLMs, forming what is referred to as an LLM chain. 
- The Agents module: allows LLMs to make informed decisions by orchestrating complex commands and actions in response to specific requests. 
- The Memory module: aids LLMs in retaining context by incorporating both short-term and long-term memory based on specific use cases. 

</details>